{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variable to use GPU\n",
    "# To limit TensorFlow to use only the first GPU (0th GPU), you can set this:\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU 0 (first GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the dataset\n",
    "data=pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Drop irrelevant columns\n",
    "data=data.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France       0   42       2       0.00              1   \n",
       "1             608     Spain       0   41       1   83807.86              1   \n",
       "2             502    France       0   42       8  159660.80              3   \n",
       "3             699    France       0   39       1       0.00              2   \n",
       "4             850     Spain       0   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France       1   39       5       0.00              2   \n",
       "9996          516    France       1   35      10   57369.61              1   \n",
       "9997          709    France       0   36       7       0.00              1   \n",
       "9998          772   Germany       1   42       3   75075.31              2   \n",
       "9999          792    France       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encode categorical variables\n",
    "label_encoder_gender=LabelEncoder()\n",
    "data['Gender']=label_encoder_gender.fit_transform(data['Gender'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Onehot encode 'Geography\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder_geo=OneHotEncoder()\n",
    "geo_encoder=onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder_geo.get_feature_names_out(['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain\n",
       "0                  1.0                0.0              0.0\n",
       "1                  0.0                0.0              1.0\n",
       "2                  1.0                0.0              0.0\n",
       "3                  1.0                0.0              0.0\n",
       "4                  0.0                0.0              1.0\n",
       "...                ...                ...              ...\n",
       "9995               1.0                0.0              0.0\n",
       "9996               1.0                0.0              0.0\n",
       "9997               1.0                0.0              0.0\n",
       "9998               0.0                1.0              0.0\n",
       "9999               1.0                0.0              0.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_encoded_df=pd.DataFrame(geo_encoder,columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "geo_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Combine one hot encoder columns with the original data\n",
    "data=pd.concat([data.drop('Geography',axis=1),geo_encoded_df],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the encoders \n",
    "with open('label_encoder_gender.pkl','wb') as file:\n",
    "    pickle.dump(label_encoder_gender,file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl','wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DiVide the dataset into indepent and dependent features\n",
    "X=data.drop('Exited',axis=1)\n",
    "y=data['Exited']\n",
    "\n",
    "## Split the data in training and tetsing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "## Scale these features\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl','wb') as file:\n",
    "    pickle.dump(scaler,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Ensure that you have X_train, y_train, X_test, and y_test loaded\n",
    "\n",
    "# Create the model function\n",
    "def create_model(neurons=32, layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create parameter grid manually\n",
    "param_grid = {\n",
    "    'neurons': [16, 32, 64, 128],\n",
    "    'layers': [1, 2, 3],\n",
    "    'epochs': [100]\n",
    "}\n",
    "\n",
    "# Set up initial best parameters and model tracker\n",
    "best_score = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Set up TensorBoard callback and EarlyStopping callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Manually loop over parameters for grid search\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Training with params: {params}\")\n",
    "    \n",
    "    model = create_model(neurons=params['neurons'], layers=params['layers'])\n",
    "    \n",
    "    # Train the model with the current set of parameters\n",
    "    history = model.fit(\n",
    "        X_train, y_train, validation_data=(X_test, y_test), epochs=params['epochs'],\n",
    "        callbacks=[tensorflow_callback, early_stopping_callback], verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Score: {score}\")\n",
    "    \n",
    "    # Update best model if necessary\n",
    "    if score[1] > best_score:  # score[1] is accuracy\n",
    "        best_score = score[1]\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Params: {best_params}\")\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('best_model.h5')\n",
    "\n",
    "# Plotting the training and validation metrics\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TensorBoard visualization\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'epochs': 100, 'layers': 1, 'neurons': 16}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 4s 8ms/step - loss: 0.5935 - accuracy: 0.6930 - val_loss: 0.4632 - val_accuracy: 0.8150\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4499 - accuracy: 0.8125 - val_loss: 0.4256 - val_accuracy: 0.8190\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4298 - accuracy: 0.8169 - val_loss: 0.4117 - val_accuracy: 0.8240\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.4166 - accuracy: 0.8232 - val_loss: 0.4003 - val_accuracy: 0.8325\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.4049 - accuracy: 0.8292 - val_loss: 0.3907 - val_accuracy: 0.8355\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3946 - accuracy: 0.8346 - val_loss: 0.3824 - val_accuracy: 0.8435\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3859 - accuracy: 0.8400 - val_loss: 0.3754 - val_accuracy: 0.8460\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3782 - accuracy: 0.8431 - val_loss: 0.3699 - val_accuracy: 0.8445\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3716 - accuracy: 0.8474 - val_loss: 0.3642 - val_accuracy: 0.8505\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3656 - accuracy: 0.8491 - val_loss: 0.3592 - val_accuracy: 0.8515\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3602 - accuracy: 0.8494 - val_loss: 0.3552 - val_accuracy: 0.8515\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3560 - accuracy: 0.8539 - val_loss: 0.3521 - val_accuracy: 0.8520\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3525 - accuracy: 0.8551 - val_loss: 0.3504 - val_accuracy: 0.8535\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3498 - accuracy: 0.8575 - val_loss: 0.3483 - val_accuracy: 0.8550\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3472 - accuracy: 0.8579 - val_loss: 0.3475 - val_accuracy: 0.8555\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3459 - accuracy: 0.8584 - val_loss: 0.3464 - val_accuracy: 0.8555\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3446 - accuracy: 0.8580 - val_loss: 0.3459 - val_accuracy: 0.8570\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3430 - accuracy: 0.8584 - val_loss: 0.3450 - val_accuracy: 0.8585\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3426 - accuracy: 0.8569 - val_loss: 0.3445 - val_accuracy: 0.8580\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8597 - val_loss: 0.3441 - val_accuracy: 0.8580\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8597 - val_loss: 0.3445 - val_accuracy: 0.8565\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3403 - accuracy: 0.8601 - val_loss: 0.3447 - val_accuracy: 0.8580\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3398 - accuracy: 0.8594 - val_loss: 0.3437 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8597 - val_loss: 0.3447 - val_accuracy: 0.8590\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3388 - accuracy: 0.8606 - val_loss: 0.3445 - val_accuracy: 0.8575\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3382 - accuracy: 0.8596 - val_loss: 0.3458 - val_accuracy: 0.8540\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3381 - accuracy: 0.8621 - val_loss: 0.3446 - val_accuracy: 0.8585\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3375 - accuracy: 0.8606 - val_loss: 0.3452 - val_accuracy: 0.8605\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3373 - accuracy: 0.8619 - val_loss: 0.3444 - val_accuracy: 0.8585\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8606 - val_loss: 0.3441 - val_accuracy: 0.8575\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8611 - val_loss: 0.3435 - val_accuracy: 0.8595\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3369 - accuracy: 0.8600 - val_loss: 0.3442 - val_accuracy: 0.8575\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8615 - val_loss: 0.3435 - val_accuracy: 0.8575\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3360 - accuracy: 0.8609 - val_loss: 0.3432 - val_accuracy: 0.8585\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3356 - accuracy: 0.8618 - val_loss: 0.3440 - val_accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.8625 - val_loss: 0.3437 - val_accuracy: 0.8545\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8608 - val_loss: 0.3432 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3350 - accuracy: 0.8630 - val_loss: 0.3430 - val_accuracy: 0.8565\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.8620 - val_loss: 0.3433 - val_accuracy: 0.8595\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.8626 - val_loss: 0.3421 - val_accuracy: 0.8605\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.8619 - val_loss: 0.3428 - val_accuracy: 0.8605\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.8639 - val_loss: 0.3431 - val_accuracy: 0.8605\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3341 - accuracy: 0.8615 - val_loss: 0.3431 - val_accuracy: 0.8595\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3339 - accuracy: 0.8631 - val_loss: 0.3428 - val_accuracy: 0.8565\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3339 - accuracy: 0.8627 - val_loss: 0.3435 - val_accuracy: 0.8585\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.8634 - val_loss: 0.3422 - val_accuracy: 0.8615\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.8627 - val_loss: 0.3421 - val_accuracy: 0.8555\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8634 - val_loss: 0.3431 - val_accuracy: 0.8590\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8644 - val_loss: 0.3429 - val_accuracy: 0.8590\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.8633 - val_loss: 0.3435 - val_accuracy: 0.8585\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.8627 - val_loss: 0.3426 - val_accuracy: 0.8570\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8631 - val_loss: 0.3425 - val_accuracy: 0.8585\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3334 - accuracy: 0.8637 - val_loss: 0.3422 - val_accuracy: 0.8575\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8639 - val_loss: 0.3427 - val_accuracy: 0.8575\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8614 - val_loss: 0.3420 - val_accuracy: 0.8575\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3326 - accuracy: 0.8626 - val_loss: 0.3415 - val_accuracy: 0.8605\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8648 - val_loss: 0.3425 - val_accuracy: 0.8590\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8626 - val_loss: 0.3425 - val_accuracy: 0.8605\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.8626 - val_loss: 0.3418 - val_accuracy: 0.8615\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3322 - accuracy: 0.8635 - val_loss: 0.3425 - val_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3319 - accuracy: 0.8633 - val_loss: 0.3414 - val_accuracy: 0.8605\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3322 - accuracy: 0.8618 - val_loss: 0.3410 - val_accuracy: 0.8600\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3320 - accuracy: 0.8659 - val_loss: 0.3426 - val_accuracy: 0.8580\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8641 - val_loss: 0.3412 - val_accuracy: 0.8600\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8633 - val_loss: 0.3415 - val_accuracy: 0.8595\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.8633 - val_loss: 0.3415 - val_accuracy: 0.8595\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3313 - accuracy: 0.8639 - val_loss: 0.3401 - val_accuracy: 0.8600\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8641 - val_loss: 0.3409 - val_accuracy: 0.8585\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3314 - accuracy: 0.8631 - val_loss: 0.3412 - val_accuracy: 0.8585\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8636 - val_loss: 0.3409 - val_accuracy: 0.8585\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3309 - accuracy: 0.8636 - val_loss: 0.3400 - val_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.8646 - val_loss: 0.3410 - val_accuracy: 0.8580\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3305 - accuracy: 0.8645 - val_loss: 0.3411 - val_accuracy: 0.8595\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3307 - accuracy: 0.8636 - val_loss: 0.3428 - val_accuracy: 0.8585\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3304 - accuracy: 0.8639 - val_loss: 0.3410 - val_accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.8654 - val_loss: 0.3430 - val_accuracy: 0.8605\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3308 - accuracy: 0.8641 - val_loss: 0.3402 - val_accuracy: 0.8585\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8640 - val_loss: 0.3408 - val_accuracy: 0.8590\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3306 - accuracy: 0.8643 - val_loss: 0.3409 - val_accuracy: 0.8585\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8634 - val_loss: 0.3403 - val_accuracy: 0.8575\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8664 - val_loss: 0.3417 - val_accuracy: 0.8610\n",
      "Score: [0.33997854590415955, 0.8600000143051147]\n",
      "Training with params: {'epochs': 100, 'layers': 1, 'neurons': 32}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.4980 - accuracy: 0.7670 - val_loss: 0.4211 - val_accuracy: 0.8200\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.4226 - accuracy: 0.8198 - val_loss: 0.3998 - val_accuracy: 0.8320\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4019 - accuracy: 0.8357 - val_loss: 0.3820 - val_accuracy: 0.8380\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3845 - accuracy: 0.8449 - val_loss: 0.3686 - val_accuracy: 0.8465\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3714 - accuracy: 0.8512 - val_loss: 0.3600 - val_accuracy: 0.8510\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3625 - accuracy: 0.8514 - val_loss: 0.3553 - val_accuracy: 0.8545\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3569 - accuracy: 0.8526 - val_loss: 0.3513 - val_accuracy: 0.8565\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3533 - accuracy: 0.8554 - val_loss: 0.3504 - val_accuracy: 0.8525\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3501 - accuracy: 0.8572 - val_loss: 0.3488 - val_accuracy: 0.8570\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.8562 - val_loss: 0.3510 - val_accuracy: 0.8550\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3466 - accuracy: 0.8579 - val_loss: 0.3474 - val_accuracy: 0.8585\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3453 - accuracy: 0.8564 - val_loss: 0.3469 - val_accuracy: 0.8585\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8583 - val_loss: 0.3476 - val_accuracy: 0.8535\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8612 - val_loss: 0.3469 - val_accuracy: 0.8555\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3418 - accuracy: 0.8610 - val_loss: 0.3441 - val_accuracy: 0.8570\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3405 - accuracy: 0.8597 - val_loss: 0.3463 - val_accuracy: 0.8570\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3403 - accuracy: 0.8597 - val_loss: 0.3465 - val_accuracy: 0.8600\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8615 - val_loss: 0.3456 - val_accuracy: 0.8585\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3380 - accuracy: 0.8614 - val_loss: 0.3444 - val_accuracy: 0.8595\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8612 - val_loss: 0.3463 - val_accuracy: 0.8545\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8593 - val_loss: 0.3460 - val_accuracy: 0.8545\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3373 - accuracy: 0.8610 - val_loss: 0.3441 - val_accuracy: 0.8605\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3368 - accuracy: 0.8609 - val_loss: 0.3442 - val_accuracy: 0.8595\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8612 - val_loss: 0.3446 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3360 - accuracy: 0.8622 - val_loss: 0.3435 - val_accuracy: 0.8585\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3350 - accuracy: 0.8622 - val_loss: 0.3451 - val_accuracy: 0.8585\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3344 - accuracy: 0.8639 - val_loss: 0.3444 - val_accuracy: 0.8610\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3346 - accuracy: 0.8618 - val_loss: 0.3432 - val_accuracy: 0.8580\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3338 - accuracy: 0.8626 - val_loss: 0.3441 - val_accuracy: 0.8605\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3335 - accuracy: 0.8644 - val_loss: 0.3429 - val_accuracy: 0.8580\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8619 - val_loss: 0.3417 - val_accuracy: 0.8605\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3327 - accuracy: 0.8625 - val_loss: 0.3427 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3321 - accuracy: 0.8627 - val_loss: 0.3428 - val_accuracy: 0.8620\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3320 - accuracy: 0.8619 - val_loss: 0.3425 - val_accuracy: 0.8610\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8635 - val_loss: 0.3414 - val_accuracy: 0.8630\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8641 - val_loss: 0.3423 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.8629 - val_loss: 0.3419 - val_accuracy: 0.8620\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8633 - val_loss: 0.3434 - val_accuracy: 0.8600\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3306 - accuracy: 0.8633 - val_loss: 0.3423 - val_accuracy: 0.8615\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3299 - accuracy: 0.8622 - val_loss: 0.3416 - val_accuracy: 0.8540\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8640 - val_loss: 0.3438 - val_accuracy: 0.8615\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.8652 - val_loss: 0.3426 - val_accuracy: 0.8585\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3291 - accuracy: 0.8652 - val_loss: 0.3415 - val_accuracy: 0.8615\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.8641 - val_loss: 0.3396 - val_accuracy: 0.8605\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8668 - val_loss: 0.3405 - val_accuracy: 0.8620\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3287 - accuracy: 0.8631 - val_loss: 0.3418 - val_accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8620 - val_loss: 0.3391 - val_accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3272 - accuracy: 0.8643 - val_loss: 0.3390 - val_accuracy: 0.8595\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3271 - accuracy: 0.8646 - val_loss: 0.3408 - val_accuracy: 0.8635\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3270 - accuracy: 0.8645 - val_loss: 0.3405 - val_accuracy: 0.8625\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3270 - accuracy: 0.8656 - val_loss: 0.3406 - val_accuracy: 0.8645\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3263 - accuracy: 0.8650 - val_loss: 0.3394 - val_accuracy: 0.8650\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3262 - accuracy: 0.8637 - val_loss: 0.3394 - val_accuracy: 0.8640\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3256 - accuracy: 0.8650 - val_loss: 0.3377 - val_accuracy: 0.8610\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3250 - accuracy: 0.8664 - val_loss: 0.3385 - val_accuracy: 0.8585\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8634 - val_loss: 0.3373 - val_accuracy: 0.8640\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.3248 - accuracy: 0.8660 - val_loss: 0.3393 - val_accuracy: 0.8595\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8635 - val_loss: 0.3373 - val_accuracy: 0.8620\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8668 - val_loss: 0.3370 - val_accuracy: 0.8605\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8668 - val_loss: 0.3356 - val_accuracy: 0.8660\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.8650 - val_loss: 0.3366 - val_accuracy: 0.8635\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8662 - val_loss: 0.3360 - val_accuracy: 0.8625\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3234 - accuracy: 0.8655 - val_loss: 0.3350 - val_accuracy: 0.8620\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8650 - val_loss: 0.3374 - val_accuracy: 0.8635\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3232 - accuracy: 0.8652 - val_loss: 0.3370 - val_accuracy: 0.8620\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3228 - accuracy: 0.8659 - val_loss: 0.3376 - val_accuracy: 0.8650\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3231 - accuracy: 0.8649 - val_loss: 0.3366 - val_accuracy: 0.8605\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.8668 - val_loss: 0.3339 - val_accuracy: 0.8635\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3219 - accuracy: 0.8661 - val_loss: 0.3368 - val_accuracy: 0.8635\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3223 - accuracy: 0.8662 - val_loss: 0.3363 - val_accuracy: 0.8660\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3222 - accuracy: 0.8648 - val_loss: 0.3355 - val_accuracy: 0.8615\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8676 - val_loss: 0.3359 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3215 - accuracy: 0.8641 - val_loss: 0.3338 - val_accuracy: 0.8635\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3212 - accuracy: 0.8662 - val_loss: 0.3370 - val_accuracy: 0.8580\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.8648 - val_loss: 0.3354 - val_accuracy: 0.8625\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3212 - accuracy: 0.8655 - val_loss: 0.3356 - val_accuracy: 0.8635\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.8658 - val_loss: 0.3347 - val_accuracy: 0.8625\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3207 - accuracy: 0.8649 - val_loss: 0.3363 - val_accuracy: 0.8635\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3206 - accuracy: 0.8658 - val_loss: 0.3336 - val_accuracy: 0.8655\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3204 - accuracy: 0.8629 - val_loss: 0.3356 - val_accuracy: 0.8610\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3360 - val_accuracy: 0.8615\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3191 - accuracy: 0.8668 - val_loss: 0.3360 - val_accuracy: 0.8595\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3199 - accuracy: 0.8639 - val_loss: 0.3356 - val_accuracy: 0.8620\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3192 - accuracy: 0.8676 - val_loss: 0.3353 - val_accuracy: 0.8640\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.8677 - val_loss: 0.3347 - val_accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3193 - accuracy: 0.8658 - val_loss: 0.3354 - val_accuracy: 0.8675\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8651 - val_loss: 0.3339 - val_accuracy: 0.8655\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3187 - accuracy: 0.8670 - val_loss: 0.3353 - val_accuracy: 0.8650\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3185 - accuracy: 0.8668 - val_loss: 0.3366 - val_accuracy: 0.8625\n",
      "Score: [0.33355456590652466, 0.8654999732971191]\n",
      "Training with params: {'epochs': 100, 'layers': 1, 'neurons': 64}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 9ms/step - loss: 0.4671 - accuracy: 0.8015 - val_loss: 0.4061 - val_accuracy: 0.8220\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4088 - accuracy: 0.8260 - val_loss: 0.3833 - val_accuracy: 0.8355\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3856 - accuracy: 0.8419 - val_loss: 0.3670 - val_accuracy: 0.8445\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3686 - accuracy: 0.8480 - val_loss: 0.3564 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3582 - accuracy: 0.8528 - val_loss: 0.3516 - val_accuracy: 0.8515\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8561 - val_loss: 0.3509 - val_accuracy: 0.8550\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3473 - accuracy: 0.8546 - val_loss: 0.3470 - val_accuracy: 0.8555\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8561 - val_loss: 0.3478 - val_accuracy: 0.8575\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3427 - accuracy: 0.8575 - val_loss: 0.3476 - val_accuracy: 0.8575\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3407 - accuracy: 0.8591 - val_loss: 0.3477 - val_accuracy: 0.8545\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8593 - val_loss: 0.3483 - val_accuracy: 0.8570\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8591 - val_loss: 0.3475 - val_accuracy: 0.8585\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3383 - accuracy: 0.8575 - val_loss: 0.3467 - val_accuracy: 0.8565\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3369 - accuracy: 0.8583 - val_loss: 0.3456 - val_accuracy: 0.8550\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3362 - accuracy: 0.8576 - val_loss: 0.3439 - val_accuracy: 0.8585\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3355 - accuracy: 0.8584 - val_loss: 0.3441 - val_accuracy: 0.8570\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8589 - val_loss: 0.3445 - val_accuracy: 0.8635\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.8599 - val_loss: 0.3450 - val_accuracy: 0.8600\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3336 - accuracy: 0.8594 - val_loss: 0.3478 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3333 - accuracy: 0.8604 - val_loss: 0.3457 - val_accuracy: 0.8570\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3326 - accuracy: 0.8605 - val_loss: 0.3456 - val_accuracy: 0.8620\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3327 - accuracy: 0.8615 - val_loss: 0.3455 - val_accuracy: 0.8570\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3317 - accuracy: 0.8626 - val_loss: 0.3467 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8618 - val_loss: 0.3462 - val_accuracy: 0.8580\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8618 - val_loss: 0.3449 - val_accuracy: 0.8600\n",
      "Score: [0.3438989520072937, 0.8585000038146973]\n",
      "Training with params: {'epochs': 100, 'layers': 1, 'neurons': 128}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 9ms/step - loss: 0.4450 - accuracy: 0.8100 - val_loss: 0.3968 - val_accuracy: 0.8270\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3952 - accuracy: 0.8344 - val_loss: 0.3700 - val_accuracy: 0.8450\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3685 - accuracy: 0.8475 - val_loss: 0.3558 - val_accuracy: 0.8545\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3557 - accuracy: 0.8559 - val_loss: 0.3510 - val_accuracy: 0.8565\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3485 - accuracy: 0.8569 - val_loss: 0.3527 - val_accuracy: 0.8525\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3448 - accuracy: 0.8599 - val_loss: 0.3504 - val_accuracy: 0.8560\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8583 - val_loss: 0.3491 - val_accuracy: 0.8590\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3405 - accuracy: 0.8599 - val_loss: 0.3470 - val_accuracy: 0.8545\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3393 - accuracy: 0.8601 - val_loss: 0.3461 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3377 - accuracy: 0.8606 - val_loss: 0.3471 - val_accuracy: 0.8620\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3370 - accuracy: 0.8600 - val_loss: 0.3443 - val_accuracy: 0.8600\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.8615 - val_loss: 0.3468 - val_accuracy: 0.8585\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8629 - val_loss: 0.3460 - val_accuracy: 0.8565\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8610 - val_loss: 0.3446 - val_accuracy: 0.8590\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8600 - val_loss: 0.3448 - val_accuracy: 0.8595\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.8626 - val_loss: 0.3475 - val_accuracy: 0.8565\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8637 - val_loss: 0.3454 - val_accuracy: 0.8605\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8656 - val_loss: 0.3450 - val_accuracy: 0.8580\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8640 - val_loss: 0.3457 - val_accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3295 - accuracy: 0.8644 - val_loss: 0.3427 - val_accuracy: 0.8610\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3282 - accuracy: 0.8664 - val_loss: 0.3450 - val_accuracy: 0.8585\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3282 - accuracy: 0.8635 - val_loss: 0.3430 - val_accuracy: 0.8605\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3270 - accuracy: 0.8652 - val_loss: 0.3441 - val_accuracy: 0.8635\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3270 - accuracy: 0.8636 - val_loss: 0.3468 - val_accuracy: 0.8550\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8674 - val_loss: 0.3447 - val_accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8649 - val_loss: 0.3464 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3252 - accuracy: 0.8656 - val_loss: 0.3449 - val_accuracy: 0.8565\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8652 - val_loss: 0.3419 - val_accuracy: 0.8680\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3241 - accuracy: 0.8683 - val_loss: 0.3463 - val_accuracy: 0.8615\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3230 - accuracy: 0.8666 - val_loss: 0.3426 - val_accuracy: 0.8630\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3226 - accuracy: 0.8691 - val_loss: 0.3438 - val_accuracy: 0.8625\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3215 - accuracy: 0.8699 - val_loss: 0.3418 - val_accuracy: 0.8610\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3210 - accuracy: 0.8666 - val_loss: 0.3463 - val_accuracy: 0.8575\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3205 - accuracy: 0.8686 - val_loss: 0.3423 - val_accuracy: 0.8615\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3189 - accuracy: 0.8711 - val_loss: 0.3427 - val_accuracy: 0.8605\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3185 - accuracy: 0.8698 - val_loss: 0.3413 - val_accuracy: 0.8595\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3186 - accuracy: 0.8681 - val_loss: 0.3395 - val_accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3161 - accuracy: 0.8692 - val_loss: 0.3439 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3158 - accuracy: 0.8690 - val_loss: 0.3393 - val_accuracy: 0.8660\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3148 - accuracy: 0.8704 - val_loss: 0.3427 - val_accuracy: 0.8615\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3133 - accuracy: 0.8701 - val_loss: 0.3380 - val_accuracy: 0.8635\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3145 - accuracy: 0.8699 - val_loss: 0.3394 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3120 - accuracy: 0.8727 - val_loss: 0.3416 - val_accuracy: 0.8610\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3118 - accuracy: 0.8691 - val_loss: 0.3465 - val_accuracy: 0.8615\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3125 - accuracy: 0.8700 - val_loss: 0.3393 - val_accuracy: 0.8610\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3117 - accuracy: 0.8719 - val_loss: 0.3411 - val_accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3111 - accuracy: 0.8710 - val_loss: 0.3408 - val_accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3101 - accuracy: 0.8714 - val_loss: 0.3418 - val_accuracy: 0.8615\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3092 - accuracy: 0.8723 - val_loss: 0.3431 - val_accuracy: 0.8595\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3081 - accuracy: 0.8719 - val_loss: 0.3382 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.8701 - val_loss: 0.3397 - val_accuracy: 0.8645\n",
      "Score: [0.3379535377025604, 0.8634999990463257]\n",
      "Training with params: {'epochs': 100, 'layers': 2, 'neurons': 16}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 9ms/step - loss: 0.5036 - accuracy: 0.7775 - val_loss: 0.4367 - val_accuracy: 0.8155\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4389 - accuracy: 0.8091 - val_loss: 0.4192 - val_accuracy: 0.8180\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4245 - accuracy: 0.8179 - val_loss: 0.4071 - val_accuracy: 0.8200\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4097 - accuracy: 0.8242 - val_loss: 0.3958 - val_accuracy: 0.8315\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3914 - accuracy: 0.8338 - val_loss: 0.3801 - val_accuracy: 0.8415\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3726 - accuracy: 0.8430 - val_loss: 0.3692 - val_accuracy: 0.8470\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3595 - accuracy: 0.8549 - val_loss: 0.3578 - val_accuracy: 0.8515\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3506 - accuracy: 0.8553 - val_loss: 0.3569 - val_accuracy: 0.8540\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3457 - accuracy: 0.8590 - val_loss: 0.3517 - val_accuracy: 0.8530\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8605 - val_loss: 0.3500 - val_accuracy: 0.8555\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3393 - accuracy: 0.8650 - val_loss: 0.3491 - val_accuracy: 0.8555\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3373 - accuracy: 0.8619 - val_loss: 0.3466 - val_accuracy: 0.8575\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3354 - accuracy: 0.8645 - val_loss: 0.3459 - val_accuracy: 0.8585\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3340 - accuracy: 0.8646 - val_loss: 0.3503 - val_accuracy: 0.8585\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8664 - val_loss: 0.3441 - val_accuracy: 0.8595\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3317 - accuracy: 0.8633 - val_loss: 0.3441 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3307 - accuracy: 0.8648 - val_loss: 0.3453 - val_accuracy: 0.8600\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.8646 - val_loss: 0.3430 - val_accuracy: 0.8605\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.8661 - val_loss: 0.3440 - val_accuracy: 0.8605\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3278 - accuracy: 0.8668 - val_loss: 0.3473 - val_accuracy: 0.8605\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3276 - accuracy: 0.8643 - val_loss: 0.3433 - val_accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3275 - accuracy: 0.8656 - val_loss: 0.3454 - val_accuracy: 0.8620\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3261 - accuracy: 0.8658 - val_loss: 0.3447 - val_accuracy: 0.8615\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8674 - val_loss: 0.3425 - val_accuracy: 0.8625\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8658 - val_loss: 0.3457 - val_accuracy: 0.8640\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8673 - val_loss: 0.3490 - val_accuracy: 0.8625\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.8665 - val_loss: 0.3464 - val_accuracy: 0.8590\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3240 - accuracy: 0.8683 - val_loss: 0.3424 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3237 - accuracy: 0.8660 - val_loss: 0.3434 - val_accuracy: 0.8590\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3229 - accuracy: 0.8676 - val_loss: 0.3438 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3220 - accuracy: 0.8683 - val_loss: 0.3427 - val_accuracy: 0.8605\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3219 - accuracy: 0.8686 - val_loss: 0.3442 - val_accuracy: 0.8595\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3220 - accuracy: 0.8704 - val_loss: 0.3492 - val_accuracy: 0.8600\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3217 - accuracy: 0.8675 - val_loss: 0.3434 - val_accuracy: 0.8625\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8679 - val_loss: 0.3444 - val_accuracy: 0.8625\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3209 - accuracy: 0.8680 - val_loss: 0.3428 - val_accuracy: 0.8600\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3207 - accuracy: 0.8675 - val_loss: 0.3444 - val_accuracy: 0.8600\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3205 - accuracy: 0.8704 - val_loss: 0.3440 - val_accuracy: 0.8595\n",
      "Score: [0.34244614839553833, 0.8629999756813049]\n",
      "Training with params: {'epochs': 100, 'layers': 2, 'neurons': 32}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.4733 - accuracy: 0.7922 - val_loss: 0.4058 - val_accuracy: 0.8225\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.4082 - accuracy: 0.8291 - val_loss: 0.3757 - val_accuracy: 0.8435\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3736 - accuracy: 0.8482 - val_loss: 0.3569 - val_accuracy: 0.8530\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3530 - accuracy: 0.8543 - val_loss: 0.3530 - val_accuracy: 0.8535\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3445 - accuracy: 0.8593 - val_loss: 0.3480 - val_accuracy: 0.8580\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3396 - accuracy: 0.8616 - val_loss: 0.3418 - val_accuracy: 0.8590\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3372 - accuracy: 0.8621 - val_loss: 0.3510 - val_accuracy: 0.8575\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3350 - accuracy: 0.8620 - val_loss: 0.3435 - val_accuracy: 0.8575\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.8648 - val_loss: 0.3398 - val_accuracy: 0.8590\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3296 - accuracy: 0.8619 - val_loss: 0.3418 - val_accuracy: 0.8595\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3289 - accuracy: 0.8641 - val_loss: 0.3418 - val_accuracy: 0.8565\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3273 - accuracy: 0.8630 - val_loss: 0.3412 - val_accuracy: 0.8615\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8655 - val_loss: 0.3413 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3247 - accuracy: 0.8654 - val_loss: 0.3420 - val_accuracy: 0.8640\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3226 - accuracy: 0.8687 - val_loss: 0.3423 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8673 - val_loss: 0.3431 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3206 - accuracy: 0.8677 - val_loss: 0.3411 - val_accuracy: 0.8605\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.8675 - val_loss: 0.3411 - val_accuracy: 0.8580\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3184 - accuracy: 0.8687 - val_loss: 0.3436 - val_accuracy: 0.8580\n",
      "Score: [0.3397965431213379, 0.859000027179718]\n",
      "Training with params: {'epochs': 100, 'layers': 2, 'neurons': 64}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.4473 - accuracy: 0.8077 - val_loss: 0.3943 - val_accuracy: 0.8295\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3851 - accuracy: 0.8381 - val_loss: 0.3574 - val_accuracy: 0.8500\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3564 - accuracy: 0.8551 - val_loss: 0.3472 - val_accuracy: 0.8560\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3450 - accuracy: 0.8583 - val_loss: 0.3455 - val_accuracy: 0.8575\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3399 - accuracy: 0.8605 - val_loss: 0.3419 - val_accuracy: 0.8615\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3356 - accuracy: 0.8618 - val_loss: 0.3469 - val_accuracy: 0.8575\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8633 - val_loss: 0.3428 - val_accuracy: 0.8630\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3289 - accuracy: 0.8631 - val_loss: 0.3444 - val_accuracy: 0.8605\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8639 - val_loss: 0.3422 - val_accuracy: 0.8595\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.8685 - val_loss: 0.3406 - val_accuracy: 0.8605\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3210 - accuracy: 0.8656 - val_loss: 0.3392 - val_accuracy: 0.8590\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3199 - accuracy: 0.8674 - val_loss: 0.3398 - val_accuracy: 0.8585\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3184 - accuracy: 0.8661 - val_loss: 0.3394 - val_accuracy: 0.8610\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3162 - accuracy: 0.8680 - val_loss: 0.3385 - val_accuracy: 0.8650\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3123 - accuracy: 0.8691 - val_loss: 0.3471 - val_accuracy: 0.8545\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.8711 - val_loss: 0.3366 - val_accuracy: 0.8610\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8706 - val_loss: 0.3427 - val_accuracy: 0.8615\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3071 - accuracy: 0.8712 - val_loss: 0.3413 - val_accuracy: 0.8550\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3042 - accuracy: 0.8739 - val_loss: 0.3539 - val_accuracy: 0.8565\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3050 - accuracy: 0.8717 - val_loss: 0.3450 - val_accuracy: 0.8525\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3020 - accuracy: 0.8725 - val_loss: 0.3403 - val_accuracy: 0.8595\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.8749 - val_loss: 0.3454 - val_accuracy: 0.8550\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3006 - accuracy: 0.8741 - val_loss: 0.3423 - val_accuracy: 0.8595\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2956 - accuracy: 0.8760 - val_loss: 0.3470 - val_accuracy: 0.8595\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.2961 - accuracy: 0.8759 - val_loss: 0.3514 - val_accuracy: 0.8470\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2951 - accuracy: 0.8770 - val_loss: 0.3574 - val_accuracy: 0.8450\n",
      "Score: [0.33659717440605164, 0.8610000014305115]\n",
      "Training with params: {'epochs': 100, 'layers': 2, 'neurons': 128}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.4275 - accuracy: 0.8226 - val_loss: 0.3827 - val_accuracy: 0.8460\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3610 - accuracy: 0.8506 - val_loss: 0.3461 - val_accuracy: 0.8595\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3445 - accuracy: 0.8605 - val_loss: 0.3430 - val_accuracy: 0.8555\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3375 - accuracy: 0.8621 - val_loss: 0.3398 - val_accuracy: 0.8620\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3327 - accuracy: 0.8611 - val_loss: 0.3400 - val_accuracy: 0.8580\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3307 - accuracy: 0.8630 - val_loss: 0.3373 - val_accuracy: 0.8590\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.8662 - val_loss: 0.3418 - val_accuracy: 0.8645\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3228 - accuracy: 0.8637 - val_loss: 0.3429 - val_accuracy: 0.8575\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.8692 - val_loss: 0.3446 - val_accuracy: 0.8605\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3163 - accuracy: 0.8654 - val_loss: 0.3444 - val_accuracy: 0.8570\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3138 - accuracy: 0.8675 - val_loss: 0.3410 - val_accuracy: 0.8595\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3115 - accuracy: 0.8710 - val_loss: 0.3449 - val_accuracy: 0.8595\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3090 - accuracy: 0.8710 - val_loss: 0.3459 - val_accuracy: 0.8570\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3043 - accuracy: 0.8716 - val_loss: 0.3404 - val_accuracy: 0.8605\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3034 - accuracy: 0.8736 - val_loss: 0.3423 - val_accuracy: 0.8595\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2995 - accuracy: 0.8780 - val_loss: 0.3461 - val_accuracy: 0.8550\n",
      "Score: [0.3373092710971832, 0.859000027179718]\n",
      "Training with params: {'epochs': 100, 'layers': 3, 'neurons': 16}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.5007 - accuracy: 0.7844 - val_loss: 0.4234 - val_accuracy: 0.8125\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.4192 - accuracy: 0.8149 - val_loss: 0.3885 - val_accuracy: 0.8335\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3881 - accuracy: 0.8317 - val_loss: 0.3667 - val_accuracy: 0.8450\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.3648 - accuracy: 0.8455 - val_loss: 0.3572 - val_accuracy: 0.8470\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3519 - accuracy: 0.8541 - val_loss: 0.3530 - val_accuracy: 0.8490\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.3474 - accuracy: 0.8531 - val_loss: 0.3488 - val_accuracy: 0.8555\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3423 - accuracy: 0.8564 - val_loss: 0.3481 - val_accuracy: 0.8570\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3396 - accuracy: 0.8575 - val_loss: 0.3457 - val_accuracy: 0.8590\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3367 - accuracy: 0.8580 - val_loss: 0.3452 - val_accuracy: 0.8585\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3341 - accuracy: 0.8591 - val_loss: 0.3446 - val_accuracy: 0.8560\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3323 - accuracy: 0.8620 - val_loss: 0.3449 - val_accuracy: 0.8565\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8622 - val_loss: 0.3430 - val_accuracy: 0.8605\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3296 - accuracy: 0.8634 - val_loss: 0.3434 - val_accuracy: 0.8575\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3282 - accuracy: 0.8631 - val_loss: 0.3410 - val_accuracy: 0.8585\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3264 - accuracy: 0.8641 - val_loss: 0.3427 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3258 - accuracy: 0.8660 - val_loss: 0.3431 - val_accuracy: 0.8560\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3248 - accuracy: 0.8637 - val_loss: 0.3429 - val_accuracy: 0.8590\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3239 - accuracy: 0.8675 - val_loss: 0.3430 - val_accuracy: 0.8570\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3231 - accuracy: 0.8671 - val_loss: 0.3406 - val_accuracy: 0.8645\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3225 - accuracy: 0.8683 - val_loss: 0.3414 - val_accuracy: 0.8590\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3217 - accuracy: 0.8643 - val_loss: 0.3420 - val_accuracy: 0.8570\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8677 - val_loss: 0.3414 - val_accuracy: 0.8580\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3205 - accuracy: 0.8661 - val_loss: 0.3401 - val_accuracy: 0.8560\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3194 - accuracy: 0.8673 - val_loss: 0.3407 - val_accuracy: 0.8615\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3185 - accuracy: 0.8679 - val_loss: 0.3390 - val_accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3165 - accuracy: 0.8695 - val_loss: 0.3410 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3173 - accuracy: 0.8687 - val_loss: 0.3414 - val_accuracy: 0.8575\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3167 - accuracy: 0.8700 - val_loss: 0.3398 - val_accuracy: 0.8630\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3162 - accuracy: 0.8708 - val_loss: 0.3428 - val_accuracy: 0.8595\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3158 - accuracy: 0.8681 - val_loss: 0.3408 - val_accuracy: 0.8575\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3146 - accuracy: 0.8708 - val_loss: 0.3410 - val_accuracy: 0.8595\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3150 - accuracy: 0.8669 - val_loss: 0.3409 - val_accuracy: 0.8615\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3135 - accuracy: 0.8694 - val_loss: 0.3449 - val_accuracy: 0.8560\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3134 - accuracy: 0.8710 - val_loss: 0.3416 - val_accuracy: 0.8580\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8689 - val_loss: 0.3422 - val_accuracy: 0.8605\n",
      "Score: [0.33895599842071533, 0.8579999804496765]\n",
      "Training with params: {'epochs': 100, 'layers': 3, 'neurons': 32}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.4716 - accuracy: 0.7915 - val_loss: 0.4036 - val_accuracy: 0.8215\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3993 - accuracy: 0.8341 - val_loss: 0.3675 - val_accuracy: 0.8500\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3621 - accuracy: 0.8491 - val_loss: 0.3450 - val_accuracy: 0.8615\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3460 - accuracy: 0.8590 - val_loss: 0.3415 - val_accuracy: 0.8625\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3398 - accuracy: 0.8595 - val_loss: 0.3434 - val_accuracy: 0.8605\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3343 - accuracy: 0.8622 - val_loss: 0.3433 - val_accuracy: 0.8595\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3475 - val_accuracy: 0.8595\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3299 - accuracy: 0.8620 - val_loss: 0.3404 - val_accuracy: 0.8620\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.8661 - val_loss: 0.3423 - val_accuracy: 0.8630\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3255 - accuracy: 0.8655 - val_loss: 0.3408 - val_accuracy: 0.8615\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3232 - accuracy: 0.8669 - val_loss: 0.3516 - val_accuracy: 0.8530\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3232 - accuracy: 0.8670 - val_loss: 0.3404 - val_accuracy: 0.8600\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.8664 - val_loss: 0.3394 - val_accuracy: 0.8600\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.8694 - val_loss: 0.3381 - val_accuracy: 0.8650\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3185 - accuracy: 0.8714 - val_loss: 0.3414 - val_accuracy: 0.8595\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3164 - accuracy: 0.8705 - val_loss: 0.3382 - val_accuracy: 0.8610\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3158 - accuracy: 0.8706 - val_loss: 0.3410 - val_accuracy: 0.8640\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3130 - accuracy: 0.8712 - val_loss: 0.3445 - val_accuracy: 0.8590\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3135 - accuracy: 0.8726 - val_loss: 0.3436 - val_accuracy: 0.8625\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3117 - accuracy: 0.8749 - val_loss: 0.3463 - val_accuracy: 0.8590\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8714 - val_loss: 0.3436 - val_accuracy: 0.8620\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3085 - accuracy: 0.8731 - val_loss: 0.3454 - val_accuracy: 0.8600\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3084 - accuracy: 0.8715 - val_loss: 0.3549 - val_accuracy: 0.8555\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3067 - accuracy: 0.8744 - val_loss: 0.3442 - val_accuracy: 0.8640\n",
      "Score: [0.3381136655807495, 0.8650000095367432]\n",
      "Training with params: {'epochs': 100, 'layers': 3, 'neurons': 64}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 3s 9ms/step - loss: 0.4247 - accuracy: 0.8209 - val_loss: 0.3609 - val_accuracy: 0.8455\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3561 - accuracy: 0.8528 - val_loss: 0.3459 - val_accuracy: 0.8580\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3440 - accuracy: 0.8589 - val_loss: 0.3442 - val_accuracy: 0.8565\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3360 - accuracy: 0.8636 - val_loss: 0.3442 - val_accuracy: 0.8570\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3317 - accuracy: 0.8609 - val_loss: 0.3424 - val_accuracy: 0.8580\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8645 - val_loss: 0.3436 - val_accuracy: 0.8620\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3233 - accuracy: 0.8661 - val_loss: 0.3413 - val_accuracy: 0.8575\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.8685 - val_loss: 0.3410 - val_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3176 - accuracy: 0.8683 - val_loss: 0.3443 - val_accuracy: 0.8595\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3161 - accuracy: 0.8676 - val_loss: 0.3463 - val_accuracy: 0.8545\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3115 - accuracy: 0.8685 - val_loss: 0.3427 - val_accuracy: 0.8555\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3103 - accuracy: 0.8673 - val_loss: 0.3423 - val_accuracy: 0.8605\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3055 - accuracy: 0.8695 - val_loss: 0.3480 - val_accuracy: 0.8535\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3050 - accuracy: 0.8723 - val_loss: 0.3435 - val_accuracy: 0.8530\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3005 - accuracy: 0.8714 - val_loss: 0.3517 - val_accuracy: 0.8585\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.2965 - accuracy: 0.8748 - val_loss: 0.3498 - val_accuracy: 0.8580\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2954 - accuracy: 0.8748 - val_loss: 0.3497 - val_accuracy: 0.8590\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.2911 - accuracy: 0.8764 - val_loss: 0.3652 - val_accuracy: 0.8550\n",
      "Score: [0.3410443365573883, 0.8600000143051147]\n",
      "Training with params: {'epochs': 100, 'layers': 3, 'neurons': 128}\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 4s 13ms/step - loss: 0.4113 - accuracy: 0.8260 - val_loss: 0.3550 - val_accuracy: 0.8525\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3506 - accuracy: 0.8549 - val_loss: 0.3537 - val_accuracy: 0.8560\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3386 - accuracy: 0.8587 - val_loss: 0.3479 - val_accuracy: 0.8535\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3307 - accuracy: 0.8629 - val_loss: 0.3500 - val_accuracy: 0.8575\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3254 - accuracy: 0.8668 - val_loss: 0.3457 - val_accuracy: 0.8595\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3209 - accuracy: 0.8662 - val_loss: 0.3401 - val_accuracy: 0.8580\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3169 - accuracy: 0.8701 - val_loss: 0.3493 - val_accuracy: 0.8565\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3155 - accuracy: 0.8685 - val_loss: 0.3609 - val_accuracy: 0.8525\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3091 - accuracy: 0.8726 - val_loss: 0.3417 - val_accuracy: 0.8580\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.3032 - accuracy: 0.8726 - val_loss: 0.3497 - val_accuracy: 0.8610\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2979 - accuracy: 0.8767 - val_loss: 0.3497 - val_accuracy: 0.8595\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2934 - accuracy: 0.8769 - val_loss: 0.3567 - val_accuracy: 0.8545\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2868 - accuracy: 0.8799 - val_loss: 0.3694 - val_accuracy: 0.8570\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2817 - accuracy: 0.8802 - val_loss: 0.3648 - val_accuracy: 0.8520\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.2775 - accuracy: 0.8826 - val_loss: 0.3655 - val_accuracy: 0.8570\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2688 - accuracy: 0.8856 - val_loss: 0.3695 - val_accuracy: 0.8515\n",
      "Score: [0.34014758467674255, 0.8579999804496765]\n",
      "Best Score: 0.8654999732971191\n",
      "Best Params: {'epochs': 100, 'layers': 1, 'neurons': 32}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Create the model function\n",
    "def create_model(neurons=32, layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create parameter grid manually\n",
    "param_grid = {\n",
    "    'neurons': [16, 32, 64, 128],\n",
    "    'layers': [1, 2, 3],\n",
    "    'epochs': [100]\n",
    "}\n",
    "\n",
    "# Manually loop over parameters\n",
    "best_score = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Training with params: {params}\")\n",
    "    \n",
    "    model = create_model(neurons=params['neurons'], layers=params['layers'])\n",
    "    \n",
    "    # Set up the TensorBoard and EarlyStopping callbacks\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorflow_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train, validation_data=(X_test, y_test), epochs=params['epochs'],\n",
    "        callbacks=[tensorflow_callback, early_stopping_callback], verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Score: {score}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if score[1] > best_score:  # score[1] is accuracy\n",
    "        best_score = score[1]\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Params: {best_params}\")\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('best_model.h5')\n",
    "\n",
    "# Optionally, you can plot or analyze the training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1cbbf052040>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100, 'layers': 1, 'neurons': 32}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the Tensorboard\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback=TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Tensorboard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17940), started 2 days, 1:38:11 ago. (Use '!kill 17940' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-117b599d70041d4b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-117b599d70041d4b\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
